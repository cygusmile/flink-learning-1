# 什么是Apache Flink？
Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。
# 用例
## 事件驱动的应用程序
### 什么是事件驱动的应用程序？
事件驱动的应用程序是一个有状态的应用程序，它从一个或多个事件流中提取事件，并通过触发计算，状态更新或外部操作对传入事件做出反应。

事件驱动的应用程序是传统应用程序设计的演变，具有独立的计算和数据存储层。在此体系结构中，应用程序从远程事务数据库读取数据并将数据持久化。
 
 传统应用程序体系结构和事件驱动应用程序之间的差异
 ![image](https://flink.apache.org/img/usecases-eventdrivenapps.png)
## 数据分析应用
分析工作从原始数据中提取信息和洞察力。传统上，分析在记录事件的有界数据集上作为批量查询或应用程序执行。为了将最新数据合并到分析结果中，必须将其添加到分析的数据集中，并重新运行查询或应用程序。结果将写入存储系统或作为报告发出。

借助先进的流处理引擎，还可以实时地执行分析。流式查询或应用程序不是读取有限数据集，而是摄取实时事件流，并在消耗事件时不断生成和更新结果。结果要么写入外部数据库，要么保持为内部状态。仪表板应用程序可以从外部数据库读取最新结果或直接查询应用程序的内部状态。

Apache Flink支持流式和批量分析应用程序，如下图所示
![image](https://flink.apache.org/img/usecases-analytics.png)
## 数据管道应用
提取 - 转换 - 加载（ETL）是在存储系统之间转换和移动数据的常用方法。通常会定期触发ETL作业，以将数据从事务数据库系统复制到分析数据库或数据仓库。

数据管道与ETL作业具有相似的用途。它们可以转换和丰富数据，并可以将数据从一个存储系统移动到另一个存 但是，它们以连续流模式运行，而不是定期触发。因此，他们能够从连续生成数据的源中读取记录，并以低延迟将其移动到目的地。例如，数据管道可能会监视文件系统目录中的新文件，并将其数据写入事件日志。另一个应用程序可能会将事件流实现到数据库，或者逐步构建和优化搜索索引。

定期ETL作业和连续数据管道之间的差异
![image](https://flink.apache.org/img/usecases-datapipelines.png)